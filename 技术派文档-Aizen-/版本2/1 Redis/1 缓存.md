# Redis的缓存

## 设计思路

Redis的缓存涉及了下面的类：

-   SitemapServiceImpl：站点地图：站点的所有url内容、PV/UV计数统计
-   UserStatisticEventListener：统计用户的粉丝、收藏、关注信息
-   CountServiceImpl：统计文章的点赞、阅读、评论数量
-   TagSettingServiceImpl：标签相关的类
-   ForumCoreAutoConfig：缓存相关的设置类

对于SitemapServiceImpl、CountServiceImpl和UserStatisticEventListener这些计数的功能类，在版本1.0中，其具体的实现都需要先添加到数据库，然后通过SQL的COUNT()函数获得具体的值。使用了Redis之后，可以通过操作Redis重写这些需求的实现。

对于TagSettingService这种单纯为了“缓存”的抽象类，原本可以使用@Cacheable注解实现功能，但是技术派仍然将Redis的代码嵌入代码实现了，有一些冗余。你可以在CountServiceImpl中看到这些缓存的使用方法，所以这一部分不会说明。

对于ForumCoreAutoConfig的配置类，内部配置了缓存器，但因为配置内容比较少，也不会说明。

## 具体实现

### 1 SitemapService

该类实现了“站点地图”和“流量记录”这两个功能。

----

#### 站点地图

你可以在这篇[知乎文章](https://zhuanlan.zhihu.com/p/441973408)中理解站点地图的意义。这里不做详细介绍。

下面是百度的站点地图文件的一个样例：

```xml
<?xml version="1.0" encoding="utf-8"?>
<!-- XML文件需以utf-8编码-->
<urlset>
<!--必填标签-->
    <url>
        <!--必填标签,这是具体某一个链接的定义入口，每一条数据都要用<url>和</url>包含在里面，这是必须的 -->
        <loc>http://www.yoursite.com/yoursite.html</loc>
        <!--必填,URL链接地址,长度不得超过256字节-->
        <lastmod>2009-12-14</lastmod>
        <!--可以不提交该标签,用来指定该链接的最后更新时间-->
        <changefreq>daily</changefreq>
        <!--可以不提交该标签,用这个标签告诉此链接可能会出现的更新频率 -->
        <priority>0.8</priority>
        <!--可以不提交该标签,用来指定此链接相对于其他链接的优先权比值，此值定于0.0-1.0之间-->
    </url>
    <url>
        <loc>http://www.yoursite.com/yoursite2.html</loc>
        <lastmod>2010-05-01</lastmod>
        <changefreq>daily</changefreq>
        <priority>0.8</priority>
    </url>
</urlset>
```

其基本内容能够包含：

-   链接的url
-   链接的更新日期
-   链接的更新频率
-   链接的权重
-   ……

在技术派中，主要在站点地图中放入了“文章的id-最后更新的时间”。

在SitemapService中，下面的几个方法提供sitemap服务：

-   查询站点信息
-   定时刷新站点信息：初始站点信息/刷新站点信息
-   更新站点信息：文章上线、文章删除/下线

**1. 查询站点信息**

其源码如下：

```java
public SiteMapVo getSiteMap() {
    // key = 文章id, value = 最后更新时间
    Map<String, Long> siteMap = RedisClient.hGetAll(SITE_MAP_CACHE_KEY, Long.class);
    if (CollectionUtils.isEmpty(siteMap)) {
        // 首次访问时，没有数据，全量初始化
        initSiteMap();
    }
    siteMap = RedisClient.hGetAll(SITE_MAP_CACHE_KEY, Long.class);
    SiteMapVo vo = initBasicSite();
    if (CollectionUtils.isEmpty(siteMap)) {
        return vo;
    }

    for (Map.Entry<String, Long> entry : siteMap.entrySet()) {
        vo.addUrl(new SiteUrlVo(host + "/article/detail/" + entry.getKey(), DateUtil.time2utc(entry.getValue())));
    }
    return vo;
}
```

可以看到，这里说明了sitemap主要的内容是“文章的id”和“最后更新时间”。

主要获取是通过RedisClient的hGetAll()方法，得到对应的“文章id-最后更新时间”，然后通过Map初始化站点地图的内容。

这个方法在SiteMapController的sitemap()方法中被调用，该方法是一个API：

```java
@RequestMapping(path = "/sitemap", produces = "application/xml;charset=utf-8")
public SiteMapVo sitemap() {
    return sitemapService.getSiteMap();
}
```

**2. 定时刷新站点信息**

SitemapService提供了定期刷新站点信息的方法，避免在Redis更新过程中出现错误，具体的源码如下：

```java
@Scheduled(cron = "0 15 5 * * ?")
public void autoRefreshCache() {
    log.info("开始刷新sitemap.xml的url地址，避免出现数据不一致问题!");
    refreshSitemap();
    log.info("刷新完成！");
}
```

```java
@Override
public void refreshSitemap() {
    initSiteMap();
}
```

```java
private synchronized void initSiteMap() {
    long lastId = 0L;
    RedisClient.del(SITE_MAP_CACHE_KEY);
    while (true) {
        // 1. 同步数据库的文章点赞信息
        List<SimpleArticleDTO> list = articleDao
            .getBaseMapper()
            .listArticlesOrderById(lastId, SCAN_SIZE);// SCAN_SIZE为100
        list.forEach(s -> countService.refreshArticleStatisticInfo(s.getId()));

        // 2. 刷新站点地图信息
        Map<String, Long> map = list.stream().collect(Collectors.toMap(
            s -> String.valueOf(s.getId()),
            s -> s.getCreateTime().getTime(),
            (a, b) -> a));
        
        RedisClient.hMSet(SITE_MAP_CACHE_KEY, map);
        if (list.size() < SCAN_SIZE) {
            break;
        }
        lastId = list.get(list.size() - 1).getId();
    }
}
```

CountService的refreshArticleStatisticInfo()方法如下：

```java
public void refreshArticleStatisticInfo(Long articleId) {
    ArticleFootCountDTO res = userFootDao.countArticleByArticleId(articleId);
    if (res == null) {
        res = new ArticleFootCountDTO();
    } else {
        res.setCommentCount(commentReadService.queryCommentCount(articleId));
    }

    RedisClient.hMSet(CountConstants.ARTICLE_STATISTIC_INFO + articleId,
                      MapUtils.create(CountConstants.COLLECTION_COUNT, res.getCollectionCount(),
                                      CountConstants.PRAISE_COUNT, res.getPraiseCount(),
                                      CountConstants.READ_COUNT, res.getReadCount(),
                                      CountConstants.COMMENT_COUNT, res.getCommentCount()
                                     )
                     );
}

```

@Scheduled用于开启一个定时任务，对于@Scheduled注解的使用方式和原理这里不做说明。

综合下来，initSiteMap()方法的流程如下：

1.  加锁，意味着当前方法只能够单线程执行；
2.  删除Redis的sitemap的信息，那么当前获取的Redis的数据为null；
3.  循环执行下面操作：
    1.  从文章id为lastId开始获取100个文章的内容；
    1.  通过“用户足迹服务”，获取文章的点赞量、阅读量、收藏量。假如没有记录则这些信息全为0；
    1.  通过“评论服务”，获取文章的评论量；
    1.  使用hMSet()方法，将文章的点赞量、阅读量、收藏量、评论量更新至Redis的sitemap中；
    1.  获取文章的id和创建时间；
    1.  使用hMSet()方法，将文章id和更新时间更新至Redis的sitemap中；
    1.  当获取的文章数量已经少于最小获取数量时，离开循环；
    1.  将当前最后一个文章的id设置为lastId；
4.  循环结束，释放锁；

**补充信息**：

-   注释说主要获取的“文章id”和“**更新时间**”，而在SimpleArticleDTO中获取时间的方法为**getCreateTime()**。但是实际上，SimpleArticleDTO的**createTime**属性底层获取的就是表中的**updateTime**属性。你可以在ArticleMapper的listArticlesOrderById()方法对应的XML中，看到具体的实现：

    ```sql
    select id, title, update_time as createTime from article
    where id > #{lastId}
    and status = ${@com.github.paicoding.forum.api.model.enums.PushStatusEnum@ONLINE.code}
    and deleted = ${@com.github.paicoding.forum.api.model.enums.YesOrNoEnum@NO.code}
    order by id asc limit #{size}
    ```

-   可以很明显意识到，这一部分功能的实现就是简单的批量增删改查，Redis的缓存使用就是如此简单。

**吐槽一下**：

-   SitemapService除了更新站点以外，还做了CountService的事情，即更新文章的计数信息。这样的代码设计违背了“单一职责原则”，不管是否对于性能有所提升，一个类就应该做好其原本的工作，从而避免增加后期的维护成本。
-   服务层：**Sitemap**Service；Controller层：**SiteMap**Controller。此处大小写不对应。

----

#### PV/UV

你可以在这篇[知乎文章](https://zhuanlan.zhihu.com/p/49329968)中了解PV/UV的定义和意义。这里不做详细介绍。

**1. 实现逻辑**

在SitemapService中，提供了下面的方法

-   saveVisitInfo(String visitIp, String path)：保存用户某一天访问某路径的信息。
-   querySiteVisitInfo(LocalDate date, String path)：查询站点某一天/总的访问信息。

对于PV/UV，使用的Redis的hash数据结构，具体设计如下：

ps：其中，存在“#{}”符号的key/field，代表由一种类型的命名规范，存在多个实例。

-   **pai_visit_info**：全局统计
    -   **pv**：站点的总pv
    -   **uv**：站点的总uv
    -   **pv_#{path}**：站点某个资源的总pv
    -   **uv_#{path}**：站点某个资源的总uv
-   **pai_visit_info_#{ip}**：对某一个ip/用户访问的统计
    -   **pv**：用户总的访问次数
    -   **pv_#{path}**：用户访问某个路径的总次数
-   **pai_visit_info_#{time}**：某日的访问统计
    -   **pv**：某日的pv
    -   **uv**：某日的uv
    -   **pv_#{path}**：某个资源的当天pv
    -   **uv_#{path}**：某个资源的当天uv
    -   **pv_#{ip}**：用户当天的访问次数
    -   **pv\_#{path}\_#{ip}**：用户对资源的当天访问次数

你可以在SitemapServiceImpl的saveVisitInfo()方法中查看具体的修改逻辑。

>   这里本来添加了其源码，但是代码的可读性比较差，加上本人的能力有限，花了将近半个小时，没能很好的改进。

值得一提的是：在saveVisitInfo()中，调用RedisClient.pipelineAction()方法创建了一个PipelineAction，该类用于批量执行Redis的命令。同时，使用了hIncrBy()方法用于增加值。大致使用如下：

```java
RedisClient.PipelineAction pipe = RedisClient.pipelineAction();
pipe.add(todayKey, "uv", (connection, key, field) -> connection.hIncrBy(key, field, 1));
pipe.add(todayKey, "uv_" + path, (connection, key, field) -> connection.hIncrBy(key, field, 1));
...
pipe.execute();
```

SitemapServiceImpl的querySiteVisitInfo()方法用于获取具体的PV/UV的信息。主要调用了RedisClient的hMGet()方法获取结果。下面是稍微修改后的代码：

```java
/**
 * 查询站点某一天or总的访问信息
 *
 * @param date 日期，为空时，表示查询所有的站点信息
 * @param path 访问路径，为空时表示查站点信息
 * @return
 */
public SiteCntVo querySiteVisitInfo(LocalDate date, String path) {
    String globalKey = SitemapConstants.SITE_VISIT_KEY;
    String day = null;
    
    String key = globalKey;
    if (date != null) {
        day = SitemapConstants.day(date);
        key = globalKey + "_" + day;
    }

    String pvField = "pv";
    String uvField = "uv";
    if (path != null) {
        pvField += "_" + path;
        uvField += "_" + path;
    }

    Map<String, Integer> map = RedisClient.hMGet(key, Arrays.asList(pvField, uvField), Integer.class);
    
    SiteCntVo siteInfo = new SiteCntVo();
    siteInfo.setDay(day);
    siteInfo.setPv(map.getOrDefault(pvField, 0));
    siteInfo.setUv(map.getOrDefault(uvField, 0));
    return siteInfo;
}
```

**吐槽一下**：

-   这一部分“代码和注释”的可读性真的太差了：
    -   在代码上，建议使用isXXX来存储判定结果，既能够减少代码缩进，又能够清楚判定的语意。
    -   在代码内部的注释中，可以看到“PV”有的大写，有的小写；有的英文和中文有间隔，有的没有；有的“pv\_”，有的“pv” + “\_”。
    -   在代码外部的注释中，一段用“#”，一段又没用。
-   saveVisitInfo()方法的代码逻辑想复杂了，建议修改。
-   querySiteVisitInfo()方法中，源码存在一行声明多个变量，建议不要这样编写代码。

### 2 信息统计

CountServiceImpl和UserStatisticEventListener提供了用户/文章的信息统计服务，主要涉及下面内容的统计：

-   用户：关注量、已发布文章、被点赞、被阅读量、被收藏、粉丝量
-   文章：被点赞、被收藏、被评论、被阅读量

整个信息统计可以分为三个部分：

-   查询：用于获取计数信息。
-   修改：用于同步计数信息。
-   刷新：因为有可能Redis执行命令出错，刷新用于保证数据的一致性。

下面逐步介绍其具体的调用逻辑。

**1. 查询**

可以看到CountServiceImpl类的下面两个方法中提供了用户和文章的查询服务：

```java
public UserStatisticInfoDTO queryUserStatisticInfo(Long userId) {
    Map<String, Integer> ans = RedisClient.hGetAll(CountConstants.USER_STATISTIC_INFO + userId, Integer.class);
    UserStatisticInfoDTO info = new UserStatisticInfoDTO();
    info.setFollowCount(ans.getOrDefault(CountConstants.FOLLOW_COUNT, 0));
    info.setArticleCount(ans.getOrDefault(CountConstants.ARTICLE_COUNT, 0));
    info.setPraiseCount(ans.getOrDefault(CountConstants.PRAISE_COUNT, 0));
    info.setCollectionCount(ans.getOrDefault(CountConstants.COLLECTION_COUNT, 0));
    info.setReadCount(ans.getOrDefault(CountConstants.READ_COUNT, 0));
    info.setFansCount(ans.getOrDefault(CountConstants.FANS_COUNT, 0));
    return info;
}
```

```java
public ArticleFootCountDTO queryArticleStatisticInfo(Long articleId) {
    Map<String, Integer> ans = RedisClient.hGetAll(CountConstants.ARTICLE_STATISTIC_INFO + articleId, Integer.class);
    ArticleFootCountDTO info = new ArticleFootCountDTO();
    info.setPraiseCount(ans.getOrDefault(CountConstants.PRAISE_COUNT, 0));
    info.setCollectionCount(ans.getOrDefault(CountConstants.COLLECTION_COUNT, 0));
    info.setCommentCount(ans.getOrDefault(CountConstants.COMMENT_COUNT, 0));
    info.setReadCount(ans.getOrDefault(CountConstants.READ_COUNT, 0));
    return info;
}
```

主要调用了RedisClient的hGetAll()方法进行数据缓存，能够代替数据库的查询，从而加快响应速度。

这两个方法在获取用户或文章内容时被调用。

>   这是一种经典的缓存设计。

**2. 修改**

主要的修改逻辑在UserStatisticEventListener类中，其代码大致如下：

```java
@EventListener(classes = NotifyMsgEvent.class)
@Async
public void notifyMsgListener(NotifyMsgEvent msgEvent) {
    switch (msgEvent.getNotifyType()) {
        case COMMENT:
        case REPLY:
            CommentDO comment = (CommentDO) msgEvent.getContent();
            RedisClient.hIncr(CountConstants.ARTICLE_STATISTIC_INFO + comment.getArticleId(), CountConstants.COMMENT_COUNT, 1);
            break;
        ...
        case FOLLOW:
            UserRelationDO relation = (UserRelationDO) msgEvent.getContent();
            // 主用户粉丝数 + 1
            RedisClient.hIncr(CountConstants.USER_STATISTIC_INFO + relation.getUserId(), CountConstants.FANS_COUNT, 1);
            // 粉丝的关注数 + 1
            RedisClient.hIncr(CountConstants.USER_STATISTIC_INFO + relation.getFollowUserId(), CountConstants.FOLLOW_COUNT, 1);
            break;
        case CANCEL_FOLLOW:
            relation = (UserRelationDO) msgEvent.getContent();
            // 主用户粉丝数 + 1
            RedisClient.hIncr(CountConstants.USER_STATISTIC_INFO + relation.getUserId(), CountConstants.FANS_COUNT, -1);
            // 粉丝的关注数 + 1
            RedisClient.hIncr(CountConstants.USER_STATISTIC_INFO + relation.getFollowUserId(), CountConstants.FOLLOW_COUNT, -1);
            break;
        default:
    }
}
```

其中主要就是跟踪用户的执行，然后进行具体的Redis数据更新操作。可见“用户的操作追踪”对于整个项目都是非常重要的。

在CountServiceImpl中，提供了一个阅读量增加方法，用于补全上述中“无法监听用户阅读文章”的操作。

```java
public void incrArticleReadCount(Long authorUserId, Long articleId) {
    // db层的计数+1
    articleDao.incrReadCount(articleId);
    // redis计数器 +1
    RedisClient.pipelineAction()
        .add(CountConstants.ARTICLE_STATISTIC_INFO + articleId, CountConstants.READ_COUNT,
             (connection, key, value) -> connection.hIncrBy(key, value, 1))
        .add(CountConstants.USER_STATISTIC_INFO + authorUserId, CountConstants.READ_COUNT,
             (connection, key, value) -> connection.hIncrBy(key, value, 1))
        .execute();
}
```

该方法在“用户获取文章内容”时被调用，具体在ArticleReadServiceImpl的queryFullArticleInfo()方法中，这里不展示代码。

由此可见，“用户的操作追踪”其实并不完善，还需要业务的改进，否则会混乱嵌入到其他的代码中，导致后期难以维护和升级。

**3. 刷新**

下面是CountServiceImpl的autoRefreshAllUserStatisticInfo()方法，用于刷新数据：

```java
@Scheduled(cron = "0 15 4 * * ?")
public void autoRefreshAllUserStatisticInfo() {
    Long now = System.currentTimeMillis();
    log.info("开始自动刷新用户统计信息");
    Long userId = 0L;
    int batchSize = 20;
    while (true) {
        List<Long> userIds = userDao.scanUserId(userId, batchSize);
        userIds.forEach(this::refreshUserStatisticInfo);
        if (userIds.size() < batchSize) {
            userId = userIds.get(userIds.size() - 1);
            break;
        } else {
            userId = userIds.get(batchSize - 1);
        }
    }
    log.info("结束自动刷新用户统计信息，共耗时: {}ms, maxUserId: {}", System.currentTimeMillis() - now, userId);
}
```

主要刷新使用了userId参数，调用refreshUserstatisticInfo()方法。下面是其源码：

```java
public void refreshUserStatisticInfo(Long userId) {
    // 用户的文章点赞数，收藏数，阅读计数
    ArticleFootCountDTO count = userFootDao.countArticleByUserId(userId);
    if (count == null) {
        count = new ArticleFootCountDTO();
    }

    // 获取关注数
    Long followCount = userRelationDao.queryUserFollowCount(userId);
    // 粉丝数
    Long fansCount = userRelationDao.queryUserFansCount(userId);

    // 查询用户发布的文章数
    Integer articleNum = articleDao.countArticleByUser(userId);

    String key = CountConstants.USER_STATISTIC_INFO + userId;
    RedisClient.hMSet(key, MapUtils.create(CountConstants.PRAISE_COUNT, count.getPraiseCount(),
                                           CountConstants.COLLECTION_COUNT, count.getCollectionCount(),
                                           CountConstants.READ_COUNT, count.getReadCount(),
                                           CountConstants.FANS_COUNT, fansCount,
                                           CountConstants.FOLLOW_COUNT, followCount,
                                           CountConstants.ARTICLE_COUNT, articleNum));
}
```

和前面的文章/站点刷新逻辑基本一致。

**吐槽一下**：

-   在“修改”的UserStatisticEventListener代码中，某些注释是错误的。
-   在“刷新”的用户统计中，和之前的文章/站点刷新逻辑相同，但是代码的实现规范不同。甚至这里没有使用常量来规范“文章的一次获取的数量限制”，个人认为，某些可能影响业务的参数，使用@Value注解，可以单独提出到配置文件中控制数值。
-   根据业务逻辑，还差某个评论的点赞量，这个也很重要才对。
